[
  {
    "path": "posts/2023-03-25-orthogonal-regression-figure/",
    "title": "Making an illustration of Orthogonal Regression",
    "description": "It's easy enough to draw a figure illustrating the distances used \nin the optimization target for an ordinary linear regression. \nGetting the corresponding illustration right for orthogonal regression\ntook me enough extra work that I wanted to share the resolution.",
    "author": [],
    "date": "2023-03-25",
    "categories": [],
    "contents": "\nOrthogonal Regression\nOrthogonal Regression is one approach to linear regression when your predictor variable(s) is not deterministic. Since the predictors are random, a best fit point on the regression line has no guarantee to share value with the predictors directly.\nOrthogonal Regression approaches this by assigning to each point the distance to the regression line/plane/… along an orthogonal projection onto that regression space. (see the final figure below for a good illustration)\nIt is a special case of Deming Regression, where you do maximum likelihood estimation of a linear model with expected errors in the predictors as well as responses, and where errors are assumed to be independent, normally distributed, and with known ratio of their variances.\nPCA computes the regression\nOne approach to orthogonal regression is by using Principal Component Analysis. While a bunch of places on the internet discuss how to find and plot the right regression line this way, much fewer sources discuss how to find the right line segments to illustrate things.\n\n\n\nGiven data in df$x and df$y, you would fit a PCA model to the data, and then use the rotation matrix and center computations to derive slope and intercept for a line of best fit.\n\n\npca = prcomp(~x + y, data=df)\no.1 = pca$rotation[2,1] / pca$rotation[1,1]\no.0 = pca$center[2] - o.1*pca$center[1]\n\nggplot(df) +\n  geom_point(aes(x,y)) +\n  geom_abline(slope=o.1, intercept=o.0) +\n  coord_fixed() + xlim(0,20) + ylim(-15,5)\n\n\n\nSo far so good. But I really want small line segments connecting the data points to the line of best fit, to illustrate what’s going on. And though it looked like my first several attempts got nowhere near a sensible result, it turned out to be a matter of different scales for different axes… The exact solution I thought would work, did - it just didn’t look like it would when I tried it on a small data set, because the slope was too steep.\n\n\north = t(pca$x[,1] %*% t(pca$rotation[,1])) + pca$center\ndf$xorth = orth[1,]\ndf$yorth = orth[2,]\nggplot(df) +\n  geom_point(aes(x,y)) +\n  geom_segment(aes(x=x,y=y,xend=xorth,yend=yorth)) +\n  geom_abline(slope=o.1, intercept=o.0) +\n  coord_fixed() + xlim(0,20) + ylim(-15,5)\n\n\n\n\n\n\n",
    "preview": "posts/2023-03-25-orthogonal-regression-figure/distill-preview.png",
    "last_modified": "2023-03-25T23:31:42-04:00",
    "input_file": "orthogonal-regression-figure.knit.md"
  },
  {
    "path": "posts/2023-02-14-student-errata/",
    "title": "Errata for Student (1908)",
    "description": "There are arithmetic errors in the paper that created Student's T-test.",
    "author": [],
    "date": "2023-02-14",
    "categories": [],
    "contents": "\nWilliam Sealy Gosset, writing as Student, famously published The Probable Error of a Mean in 1908 deriving the T-distribution and suggesting the T-test.\nIn revisiting the paper while preparing my lectures for this week I have noticed some discrepancies in the Illustration II section. Seeking out the data sources used by Student, I could verify the data used and that the discrepancy is isolated to two arithmetic errors on behalf of Student.\nThe Data\nIllustration II uses data on growing soft and hard wheat in heavy and light soil and measuring straw and corn yields from the different factors over 3 years. Student gives us:\nSoft and hard wheat data from Student (1908)From the yield measurements by Voelcker, Student extracts differences and then computes mean difference, standard deviation of the difference, and his \\(z\\) measure (that seems to be \\(\\overline{x}/s\\)).\nThe Source Data\nLooking up (scanned copies of) the Journal of the Royal Agricultural Society, I could find the data tables where Student had sourced this data set spread of 3 volumes of the Journal:\nSoft and hard wheat measurements from 1899, reported by Voelcker (1900)Soft and hard wheat measurements from 1900, reported by Voelcker (1901)Soft and hard wheat measurements from 1901, reported by Voelcker (1902)We can verify the numbers as reported by Student in these tables from Voelcker, and could digitize the data set by copying all the numbers into a data frame or tibble:\n\nyear\nsoil\nyieldtype\nseedtype\nyield\n1899\nlight\ncorn\nsoft\n7.85\n1899\nheavy\ncorn\nsoft\n8.89\n1900\nlight\ncorn\nsoft\n14.81\n1900\nheavy\ncorn\nsoft\n13.55\n1901\nlight\ncorn\nsoft\n7.48\n1901\nheavy\ncorn\nsoft\n15.39\n1899\nlight\ncorn\nhard\n7.27\n1899\nheavy\ncorn\nhard\n8.32\n1900\nlight\ncorn\nhard\n13.81\n1900\nheavy\ncorn\nhard\n13.36\n1901\nlight\ncorn\nhard\n7.97\n1901\nheavy\ncorn\nhard\n13.13\n1899\nlight\nstraw\nsoft\n12.81\n1899\nheavy\nstraw\nsoft\n12.87\n1900\nlight\nstraw\nsoft\n22.22\n1900\nheavy\nstraw\nsoft\n20.21\n1901\nlight\nstraw\nsoft\n13.97\n1901\nheavy\nstraw\nsoft\n22.57\n1899\nlight\nstraw\nhard\n10.71\n1899\nheavy\nstraw\nhard\n12.48\n1900\nlight\nstraw\nhard\n21.64\n1900\nheavy\nstraw\nhard\n20.26\n1901\nlight\nstraw\nhard\n11.71\n1901\nheavy\nstraw\nhard\n18.96\n\nFor your convenience, here is this table in a downloadable format, as well as the differences that Student focuses on, both in CSV-format.\nThe Issue\nThe discrepancy lies in the computation of the differences. Consider the straw yields in light soil in 1900 and 1901. Student states for us:\nYear\nSoft\nHard\nIncrease\n1900\n22.22\n21.64\n0.78\n1901\n13.97\n11.71\n2.66\nBut these subtractions are not accurate! 22.22-21.64=0.58 and 13.97-11.71=2.26. These miscalculations then contribute to throwing off Student’s subsequent computations.\n\n\n\nStudent also computes standard deviations as \\(\\sqrt{\\frac{1}{n}\\sum(x_i-\\overline{x})^2}\\) and not \\(\\sqrt{\\frac{1}{n-1}\\sum(x_i-\\overline{x})^2}\\), throwing the values off by a factor \\(\\sqrt{\\frac{n-1}{n}}=\\sqrt{\\frac{5}{6}}\\).\nStudent reports:\nType\nSoft Average\nHard Average\nIncrease Average\nIncrease Std Dev\n\\(z\\)\nCorn\n11.328\n10.643\n0.685\n0.778\n0.88\nStraw\n17.442\n15.927\n1.515\n1.261\n1.20\nA computation directly from the provided data instead yields, where the standard deviations and \\(z\\)-values following Student’s definitions are also included:\n\nType\nSoft Average\nHard Average\nIncrease Average\nIncrease Std Dev\nIncrease Std Dev (Student)\nz\nz (Student)\ncorn\n11.32833\n10.64333\n0.685000\n0.9197554\n0.705000\n0.7447632\n0.9716312\nstraw\n17.44167\n15.96000\n1.481667\n1.4048974\n1.644833\n1.0546440\n0.9008005\n\nI am unable to fully reconstruct Student’s stated values, not just of summary statistics for the Straw yield type (where the computation of the differences is already erroneous) but for standard deviation and \\(z\\)-value for either type. Whether or not I use the formulas given in Student (1908) I still get different values for the standard deviation.\nStudent’s T-test\nThese resulting \\(z\\)-values (computed by Student to be 0.88 and 1.20; reconstructed to either 0.745, 1.05 or 0.972, 0.901) are then used in lookup tables compiled by Student. These lookup tables correspond to computing \\(CDF_{T(n-1)}(z\\sqrt{n-1})\\) - as can be seen by Student reporting the computed \\(p=0.9465\\) for \\(z=0.88\\) and \\(p=0.9782\\) for \\(z=1.20\\). A modern approach would instead compute \\(CDF_{T(n-1)}(z\\sqrt{n})\\). Student then uses these to compute odds \\(p/(1-p)\\).\n\\(z\\)\n\\(CDF_{T(n-1)}(z\\sqrt{n-1})\\)\nOdds\n\\(CDF_{T(n-1)}(z\\sqrt{n})\\)\nOdds\n0.88\n0.9469\n17.8\n0.9582\n22.9\n1.20\n0.9782\n44.8\n0.9839\n61\n0.745\n0.9217\n11.8\n0.9362\n14.7\n1.05\n0.9671\n29.4\n0.975\n39.1\n0.972\n0.9591\n23.5\n0.9685\n30.7\n0.901\n0.95\n19\n0.9608\n24.5\nBibliography\nStudent, The Probable Error of a Mean, Biometrika (1908) jstor\nVoelcker, The Woburn Pot-culture Station, Journal of the Royal Agricultural Society of England, Series 3, Volume 61 (1900) hathitrust\nVoelcker, The Woburn Pot-culture Experiments, Journal of the Royal Agricultural Society of England, Series 3, Volume 62 (1901) hathitrust\nVoelcker, The Woburn Pot-culture Experiments, 1901, Journal of the Royal Agricultural Society of England, Series 3, Volume 63 (1902) hathitrust\n\n\n\n",
    "preview": {},
    "last_modified": "2023-02-14T10:39:22-05:00",
    "input_file": "student-errata.knit.md"
  },
  {
    "path": "posts/2020-08-08-hoeffding/",
    "title": "Hoeffding's inequality and a Bernoulli confidence interval",
    "description": "Following up on the previous article, we take a closer look at the derivation of the conservative finite sample confidence interval.",
    "author": [],
    "date": "2020-08-08",
    "categories": [],
    "preview": {},
    "last_modified": "2020-08-08T16:28:23-04:00",
    "input_file": "hoeffding.utf8.md"
  },
  {
    "path": "posts/2020-08-07-confidence-intervals/",
    "title": "Confidence intervals for Bernoulli samples",
    "description": "Empirical exploration of the sizes of two Bernoulli confidence intervals.",
    "author": [],
    "date": "2020-08-07",
    "categories": [],
    "preview": "posts/2020-08-07-confidence-intervals/distill-preview.png",
    "last_modified": "2020-08-07T17:53:07-04:00",
    "input_file": "confidence-intervals.utf8.md"
  },
  {
    "path": "posts/2020-08-04-robustness/",
    "title": "Robustness simulations in R",
    "description": "Repeating robustness tests from John D Cook's blog, but with R code instead of Python.",
    "author": [],
    "date": "2020-08-05",
    "categories": [],
    "preview": "posts/2020-08-04-robustness/distill-preview.png",
    "last_modified": "2020-08-05T14:51:12-04:00",
    "input_file": "robustness.utf8.md"
  },
  {
    "path": "posts/2020-07-24-bootstrap/",
    "title": "The Bootstrap",
    "description": "A description of the Bootstrap, and an example from \"All of Statistics\"",
    "author": [],
    "date": "2020-07-24",
    "categories": [],
    "preview": "posts/2020-07-24-bootstrap/distill-preview.png",
    "last_modified": "2020-07-27T16:13:57-04:00",
    "input_file": "bootstrap.utf8.md"
  },
  {
    "path": "posts/2020-06-13-mythbusters-navigation/",
    "title": "Mythbusters Navigation",
    "description": "A look at data from Mythbusters 12x5.",
    "author": [
      {
        "name": "Mikael Vejdemo-Johansson",
        "url": {}
      }
    ],
    "date": "2020-06-13",
    "categories": [],
    "preview": "posts/2020-06-13-mythbusters-navigation/mythbusters-navigation_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2020-06-14T12:43:48-04:00",
    "input_file": {}
  }
]
